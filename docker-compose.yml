# Bring up all the pieces necessary to run the workbench
# Data persists in Docker volumes and in local dir

# This file passes through all necessary env variables to requisite
# Docker containers and makes them available when running commands via
# `docker exec`.

version: '3.4'

services:
  database:
    image: postgres:10.10
    environment:
      POSTGRES_USER: autoscrape
      POSTGRES_PASSWORD: autoscrape
      POSTGRES_DB: autoscrape
      PGDATA: /var/lib/postgresql/data/10.10
    networks: [ 'dev' ]
    volumes:
      - dbdata:/var/lib/postgresql/data

  rabbitmq:
    image: rabbitmq:3.7.8-management
    ports: [ '15672' ] # open management port, for debugging
    networks: [ 'dev' ]
    environment:
      # Use just one CPU
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: '+S 1:1 +stbt ts +A 12'

  flask:
    build:
      context: .
      target: base
    volumes:
      - ./:/app:rw
      - virtualenvs:/root/.local/share/virtualenvs/:rw
    command: [ 'python3', 'autoscrape-server.py' ]
    ports:
      - '5000:5000'
    links:
      - rabbitmq
    depends_on: [ 'rabbitmq', 'database' ]
    networks: [ 'dev' ]
    environment:
      AUTOSCRAPE_RABBITMQ_HOST: amqp://guest:guest@rabbitmq/
      AUTOSCRAPE_DB_HOST: database
      AUTOSCRAPE_DB_USER: autoscrape
      AUTOSCRAPE_DB_PASSWORD: autoscrape

  celery:
    build:
      context: .
      target: base
    volumes:
      - ./:/app:rw
      - virtualenvs:/root/.local/share/virtualenvs/:rw
    command: [ 'celery', '-A', 'autoscrape.tasks', 'worker', '--loglevel=info' ]
    #user: nobody
    links:
      - rabbitmq
    depends_on: [ 'rabbitmq', 'flask', 'database' ]
    networks: [ 'dev' ]
    environment:
      AUTOSCRAPE_RABBITMQ_HOST: amqp://guest:guest@rabbitmq/
      AUTOSCRAPE_DB_HOST: database
      AUTOSCRAPE_DB_USER: autoscrape
      AUTOSCRAPE_DB_PASSWORD: autoscrape

networks:
  dev:
    driver: bridge

volumes:
  virtualenvs: {}
  dbdata: {}

